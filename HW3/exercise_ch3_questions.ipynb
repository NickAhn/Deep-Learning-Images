{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b64bb2c2-534a-4c17-86ab-57ea31e4346e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41504/2197491893.py:4: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1408.)\n",
      "  t1 = torch.rand(6, 3, 256, 256, names=[\"image\",\"channels\", \"rows\", \"cols\"]) # shape = [image, channels, rows, cols]\n"
     ]
    }
   ],
   "source": [
    "#Create a tensor t1 with random values that represents a batch of six RGB images of size 256 * 256.\n",
    "import torch\n",
    "\n",
    "t1 = torch.rand(6, 3, 256, 256, names=[\"image\",\"channels\", \"rows\", \"cols\"]) # shape = [image, channels, rows, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b3f693-198c-413c-8030-615a8b590320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 128, 128])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Out of the created tensor t1, extract all six images' Green channel, restricted to the first 128 * 128 pixels.\n",
    "#What would be the size of this tensor?\n",
    "greens = t1[:, 1, :128, :128]\n",
    "greens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3fd81c-bd87-4db9-a54a-2aab20c9f4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4356, 0.5421, 0.5120,  ..., 0.7801, 0.5192, 0.4242],\n",
       "         [0.4543, 0.3989, 0.5779,  ..., 0.3047, 0.6435, 0.3379],\n",
       "         [0.5669, 0.7027, 0.7576,  ..., 0.1573, 0.3877, 0.2682],\n",
       "         ...,\n",
       "         [0.5286, 0.7633, 0.6459,  ..., 0.0604, 0.6758, 0.5532],\n",
       "         [0.4828, 0.7599, 0.6221,  ..., 0.3771, 0.2502, 0.4050],\n",
       "         [0.7397, 0.3605, 0.7569,  ..., 0.2640, 0.4373, 0.7490]],\n",
       "\n",
       "        [[0.5089, 0.4332, 0.4403,  ..., 0.4514, 0.5978, 0.7571],\n",
       "         [0.6631, 0.7354, 0.4413,  ..., 0.5516, 0.4419, 0.4223],\n",
       "         [0.5577, 0.3656, 0.7312,  ..., 0.4132, 0.1600, 0.3764],\n",
       "         ...,\n",
       "         [0.2815, 0.6736, 0.6178,  ..., 0.6471, 0.5106, 0.5036],\n",
       "         [0.7933, 0.5745, 0.3343,  ..., 0.8495, 0.4645, 0.5900],\n",
       "         [0.6731, 0.6029, 0.7261,  ..., 0.3531, 0.4138, 0.7344]],\n",
       "\n",
       "        [[0.3187, 0.6612, 0.7434,  ..., 0.3688, 0.5863, 0.4267],\n",
       "         [0.2906, 0.2485, 0.8102,  ..., 0.5867, 0.8075, 0.5066],\n",
       "         [0.4890, 0.5451, 0.8738,  ..., 0.5974, 0.3785, 0.6216],\n",
       "         ...,\n",
       "         [0.7281, 0.4476, 0.7240,  ..., 0.7996, 0.5829, 0.4519],\n",
       "         [0.5087, 0.7955, 0.3885,  ..., 0.4110, 0.5177, 0.5456],\n",
       "         [0.4903, 0.3970, 0.5812,  ..., 0.6813, 0.6587, 0.4769]],\n",
       "\n",
       "        [[0.3064, 0.3977, 0.3194,  ..., 0.3751, 0.1914, 0.5910],\n",
       "         [0.3682, 0.7111, 0.5097,  ..., 0.5121, 0.2775, 0.4795],\n",
       "         [0.5853, 0.4654, 0.2782,  ..., 0.4940, 0.5250, 0.2349],\n",
       "         ...,\n",
       "         [0.4848, 0.7192, 0.4288,  ..., 0.5719, 0.7418, 0.7409],\n",
       "         [0.3338, 0.3494, 0.4960,  ..., 0.2995, 0.3027, 0.6399],\n",
       "         [0.4212, 0.6415, 0.3253,  ..., 0.5587, 0.5939, 0.5934]],\n",
       "\n",
       "        [[0.4764, 0.7473, 0.2318,  ..., 0.2931, 0.6324, 0.0908],\n",
       "         [0.6221, 0.7062, 0.6071,  ..., 0.3080, 0.3784, 0.5591],\n",
       "         [0.3530, 0.4261, 0.4005,  ..., 0.7510, 0.7350, 0.6622],\n",
       "         ...,\n",
       "         [0.4004, 0.7568, 0.6264,  ..., 0.7318, 0.0508, 0.4656],\n",
       "         [0.7638, 0.3670, 0.1717,  ..., 0.3327, 0.7221, 0.6392],\n",
       "         [0.3853, 0.5162, 0.3609,  ..., 0.6910, 0.4303, 0.7107]],\n",
       "\n",
       "        [[0.5979, 0.5330, 0.4300,  ..., 0.7546, 0.6446, 0.3847],\n",
       "         [0.5727, 0.5896, 0.6573,  ..., 0.4991, 0.7004, 0.4473],\n",
       "         [0.5127, 0.6113, 0.6741,  ..., 0.2735, 0.3520, 0.2161],\n",
       "         ...,\n",
       "         [0.5482, 0.7188, 0.5739,  ..., 0.4041, 0.4096, 0.7827],\n",
       "         [0.5545, 0.6444, 0.3984,  ..., 0.4004, 0.2491, 0.6258],\n",
       "         [0.5929, 0.5379, 0.5714,  ..., 0.4475, 0.7079, 0.3770]]],\n",
       "       names=('image', 'rows', 'cols'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In t1, compute the average of all three channels, i.e., change each image to a single channel image, by averaging\n",
    "# on all three channels in each pixel.\n",
    "#What is the size of this new tensor?\n",
    "t1.mean('channels') # Alternatively, t1.mean(1) or t1.mean(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c5b8b9-5fb3-443c-b13a-dcaf2eab5f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the tensor to contain 16 bit float values. And check its type.\n",
    "t1 = t1.to(torch.half)\n",
    "t1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a052b9ce-2da2-44a5-a7d7-d716159003eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Stride of t2 is (m,1)\\n\\n2. Stride of t3 is (n*m, n, 1)\\n\\n3. Stride of t4 is (p*n*m, n*m, m, 1)\\n\\n4. Stride = \\n\\n(n_d-1 * (n_d-2 * ... * n_1),\\n n_d-2 * (n_d-3 * ... * n_1),\\n ...\\n n_2*n_1,\\n n_1,\\n 1)\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assume that tensor t2 is of size n * m. What would be its stride?\n",
    "#Assume that tensor t3 is of size p * n * m. What would be its stride?\n",
    "#Assume that tensor t4 is of size q * p * n * m. What would be its stride?\n",
    "#Can you generalize it? That is, assuming some tensor t has size n_1 * n_2 * ... * n_d, what would be its stride?\n",
    "'''\n",
    "1. Stride of t2 is (m,1)\n",
    "\n",
    "2. Stride of t3 is (n*m, n, 1)\n",
    "\n",
    "3. Stride of t4 is (p*n*m, n*m, m, 1)\n",
    "\n",
    "4. Stride = \n",
    "\n",
    "(n_d-1 * (n_d-2 * ... * n_1),\n",
    " n_d-2 * (n_d-3 * ... * n_1),\n",
    " ...\n",
    " n_2*n_1,\n",
    " n_1,\n",
    " 1)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ed7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "51d8983b51cb53966cf1d57b70f2997549d5845143127ed5dcb4fa2b7e431139"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
