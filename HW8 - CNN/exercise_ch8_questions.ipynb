{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74488b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03cb0579-9bcf-4f0e-b222-05c78ef37ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: 50000\n",
      "Size of validation dataset: 10000\n"
     ]
    }
   ],
   "source": [
    "#Download CIFAR 10 dataset for training and validation purposes and apply the following changes on each image:\n",
    "# 1) make it a tensor\n",
    "# 2) normalize it based on the mean and standard deviation among all pixels in each channel (RGB).\n",
    "#Print the size of training and validation datasets\n",
    "\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "# Make it a tensor\n",
    "# t_cifar10 = datasets.CIFAR10(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "# t_cifar10_val = datasets.CIFAR10(data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# # # combine all images\n",
    "# imgs = torch.stack([img_t for img_t, _ in t_cifar10], dim=3) # training dataset images\n",
    "# imgs_val = torch.stack([img_t for img_t, _ in t_cifar10_val], dim=3) # validation dataset images\n",
    "\n",
    "# # # Computing mean per channel = 0.4914, 0.4822, 0.4465\n",
    "# imgs_mean = imgs.view(3,-1).mean(dim=1) # (0.4914, 0.4822, 0.4465),\n",
    "# # # Computing std = 0.2470, 0.2435, 0.2616\n",
    "# imgs_std = imgs.view(3, -1).std(dim=1) # (0.2470, 0.2435, 0.2616)\n",
    "# print(\"imgs_mean\", imgs_mean)\n",
    "# print(\"imgs_std\", imgs_std)\n",
    "\n",
    "# # # Computing mean per channel\n",
    "# imgs_val_mean = imgs_val.view(3,-1).mean(dim=1) # [0.4914, 0.4822, 0.4465]\n",
    "# # # Computing std\n",
    "# imgs_val_std = imgs_val.view(3, -1).std(dim=1) # [0.2470, 0.2435, 0.2616]\n",
    "# print(\"imgs_val_mean\", imgs_val_mean)\n",
    "# print(\"imgs_val_std:\", imgs_val_std)\n",
    "\n",
    "\n",
    "# Normalize and transform datasets\n",
    "transformed_cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n",
    "                                       transform=transforms.Compose([\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize(mean = (0.4914, 0.4822, 0.4465),\n",
    "                                                                std = (0.2470, 0.2435, 0.2616))\n",
    "                                           ]))\n",
    "\n",
    "transformed_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False,\n",
    "                                       transform=transforms.Compose([\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize(mean = (0.4942, 0.4851, 0.4504),\n",
    "                                                                std = (0.2467, 0.2429, 0.2616))\n",
    "                                           ]))\n",
    "\n",
    "\n",
    "print(\"Size of training dataset:\", len(transformed_cifar10))\n",
    "print(\"Size of validation dataset:\", len(transformed_cifar10_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90374899-4072-4ee4-a3c8-a1b0ed19ce13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar2 size 15000\n",
      "Cifar2_val size 3000\n"
     ]
    }
   ],
   "source": [
    "#We want to make a tertiary classifier that distinguishes between deers, dogs, and horses, labeled as 4, 5, and 7, resp.\n",
    "#Create the subset training and validation datasets for this purpose.\n",
    "#Print the size of these datasets.\n",
    "label_map = {4:0, 5:1, 7:2}\n",
    "class_names = [\"deers\", \"dogs\", \"horses\"]\n",
    "cifar2 = [(img, label_map[label])\n",
    "    for img, label in transformed_cifar10\n",
    "    if label in [4, 5, 7]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "    for img, label in transformed_cifar10_val\n",
    "    if label in [4, 5, 7]]\n",
    "\n",
    "print(\"Cifar2 size\", len(cifar2))\n",
    "print(\"Cifar2_val size\", len(cifar2_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e45ff49-791b-4e63-9d35-35411a0b8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a parameterized CNN with the following details. \n",
    "# The parameter is the number of output channels n after the first convolution.\n",
    "# All kernels are of size 3 by 3.\n",
    "# Convolutions must not change the height and width.\n",
    "# Each convolution is followed by hyperbolic tangent as the activation function, and max pooling of size 2 by 2.\n",
    "# Convolution ayers:\n",
    "# 1) First convolution layer works on the input RGB input. Let's assume there are n kernels in this layer.\n",
    "# 2) Second convolution layer works on the result of the preceding max pooling layer. \n",
    "#    Let's assume there are n/2 kernels in this layer.\n",
    "# 3) Third convolution layer works on the result of the preceding max pooling layer. \n",
    "#    Let's assume there are n/2 kernels in this layer. \n",
    "# Fully connected layers:\n",
    "# 1) First fully connected layer works on the result of the preceding max pooling layer. \n",
    "#    This layer is followed by hyperbolic tangent as its activation function.\n",
    "# 2) Second fully connected layer works on the result of the preceding activation function, and emits numbers associated\n",
    "#    with each class.\n",
    "# We will use negative log likelihood to compute the loss. So you may add additional layer(s) to your network.\n",
    "# Note: Since the network is parameterized (n), you'd rather define the CNN as a subclass of nn.Module.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# padding: keep the output image size the same\n",
    "class Net(nn.Module):\n",
    "    # n = number of output channels n after the first convolution\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, n, kernel_size=3, padding=1) # 3x3, 3 Channels -> n Channels\n",
    "        self.conv2 = nn.Conv2d(n, n//2, kernel_size=3, padding=1) # 3x3, n C -> n/2 C\n",
    "        self.conv3 = nn.Conv2d(n//2, n//2, kernel_size=3, padding=1) # 3x3, n/2 C -> n/2 C\n",
    "        \n",
    "        # turn multichannel 2D features into 1D vector\n",
    "        self.ch = 4 * 4 * (n//2) # W x H x num of kernels\n",
    "        self.fc1 = nn.Linear(self.ch, 32)\n",
    "        self.fc2 = nn.Linear(32, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2) # 32 x 32 x n -> kernel is 3\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2) # 16 x 16 x n/2\n",
    "        out = F.max_pool2d(torch.tanh(self.conv3(out)), 2) # 8 x 8 x n/2\n",
    "        out = out.view(-1, self.ch) # 4 x 4 x n/4 # call view to turn it into B x N vector\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1be13802-cee5-4150-b78c-49fae49d1c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of parameters in CNN with n = 16: 6419\n",
      "Total num of parameters in CNN with n = 32: 16163\n"
     ]
    }
   ],
   "source": [
    "#Create two networks as instances of the CNN you defined above, with n = 16 and n = 32 respectively. \n",
    "#Print the total number of parameters in each of these instances.\n",
    "model = Net(16)\n",
    "model2 = Net(32)\n",
    "# model = Net()\n",
    "\n",
    "numel_list_1 = [p.numel() for p in model.parameters()]\n",
    "numel_list_2 = [p.numel() for p in model2.parameters()]\n",
    "print(\"Total num of parameters in CNN with n = 16:\", sum(numel_list_1)) \n",
    "print(\"Total num of parameters in CNN with n = 32:\", sum(numel_list_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7def331-3852-4cc7-9c97-52a1d5831523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches:\n",
      "- Training data loader:  469\n",
      "- Validation data loader:  94\n"
     ]
    }
   ],
   "source": [
    "#Our training functionality is supposed to compute gradient on batches of training data, randlomy selected each time.\n",
    "#To this end, create a training data loader with batch size 32 that randomizes access to each batch.\n",
    "#Also, create a validation data loader with the same batch size that does not randomize access to each batch (no need!)\n",
    "#Print the number of batches in training and validation data loaders\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Number of batches:\")\n",
    "print(\"- Training data loader: \", len(train_loader))\n",
    "print(\"- Validation data loader: \", len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04ef16c-813a-459a-a65c-7d710321c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define your training function that receives the training loader, model, loss function, optimizer, the device (cpu/gpu), and \n",
    "# number of epochs.\n",
    "#In each epoch, you should go through each training data batch, and:\n",
    "# 1) move data to device\n",
    "# 1) compute the output batch, and accordingly the loss\n",
    "# 2) compute the gradient of loss wrt parameters, and update the parameters\n",
    "#After covering all epochs, your training function must report the training accuracy\n",
    "\n",
    "def training_loop(train_loader, model, loss_fn, optimizer, device, n_epochs):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            # move data to device\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            outputs = model(imgs) # compute output batch\n",
    "            loss = loss_fn(outputs, labels) # compute loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(datetime.datetime.now(), epoch, loss_train / len(train_loader)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60dfa4c0-173f-4afd-87ee-e602276f330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a separate function that receives the validation data loader as well as the model and computes the validation \n",
    "# accuracy of the model.\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "        print(\"Accuracy {}: {:.6f}\".format(name , correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "033e6166-15b7-4a07-aab5-eebbb2acc386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n",
      "2022-10-28 21:43:22.727780 Epoch 1, Training loss 1.0687145461151595\n",
      "2022-10-28 21:43:31.308988 Epoch 10, Training loss 0.6519320540463747\n",
      "2022-10-28 21:43:40.754543 Epoch 20, Training loss 0.5460886877101622\n",
      "2022-10-28 21:43:50.788713 Epoch 30, Training loss 0.4842876726503311\n",
      "2022-10-28 21:44:02.468107 Epoch 40, Training loss 0.44314215120984546\n",
      "2022-10-28 21:44:12.191828 Epoch 50, Training loss 0.4153198055557605\n",
      "2022-10-28 21:44:22.152500 Epoch 60, Training loss 0.3929845809237535\n",
      "2022-10-28 21:44:32.247569 Epoch 70, Training loss 0.37235292569914863\n",
      "2022-10-28 21:44:42.367197 Epoch 80, Training loss 0.352102104105802\n",
      "2022-10-28 21:44:53.637983 Epoch 90, Training loss 0.33404847685652755\n",
      "2022-10-28 21:45:04.279127 Epoch 100, Training loss 0.31983378202295\n",
      "Training and Validation Accuracy of model = Net(16)\n",
      "Accuracy train: 0.882000\n",
      "Accuracy val: 0.796667\n",
      "\n",
      "The model is slightly overfit as the training accuracy is higher than the validation accuracy.\n",
      "Overfitting happens when the model is memorizing the training data but it is not able to generalize results as well as\n",
      "for new data.\n",
      "This CNN model has shown to be more effective to generalize compared to the model in the previous homework\n",
      "given that the difference of accuracies of this model is around 8%, while the model in HW7 had a difference\n",
      "of almost 30% between training and validation accuracies.\n"
     ]
    }
   ],
   "source": [
    "#Define device dynamically based on whether CUDA is available or not.\n",
    "#Call the training function on the created training data loader, the created CNN  with n = 16, \n",
    "# negative log likelihood loss function, stochastic gradient descent optimizer,\n",
    "# the device you defined, and 100 epochs. Next, call validation accuracy function.\n",
    "#Is the model overfit? (Yes/No) Why?\n",
    "\n",
    "# move model to specified device\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")\n",
    "model = Net(16).to((device))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "n_epochs=100\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "training_loop(n_epochs=n_epochs, train_loader=train_loader, model=model, loss_fn=loss_fn, optimizer=optimizer, device=device)\n",
    "\n",
    "print(\"Training and Validation Accuracy of model = Net(16)\")\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "shuffle=False)\n",
    "validate(model=model, train_loader=train_loader, val_loader=val_loader)\n",
    "\n",
    "print('''\\nThe model is slightly overfit as the training accuracy is higher than the validation accuracy.\n",
    "Overfitting happens when the model is memorizing the training data but it is not able to generalize results as well as\n",
    "for new data.\n",
    "This CNN model has shown to be more effective to generalize compared to the model in the previous homework\n",
    "given that the difference of accuracies of this model is around 8%, while the model in HW7 had a difference\n",
    "of almost 30% between training and validation accuracies.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d2f930c-039d-4123-b90d-60fac6d68afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n",
      "2022-10-28 21:45:05.186636 Epoch 1, Training loss 1.0865204055258568\n",
      "2022-10-28 21:45:10.883717 Epoch 10, Training loss 0.7063407745767147\n",
      "2022-10-28 21:45:17.081244 Epoch 20, Training loss 0.5551923820312987\n",
      "2022-10-28 21:45:23.422732 Epoch 30, Training loss 0.4609005456275128\n",
      "2022-10-28 21:45:29.783699 Epoch 40, Training loss 0.40060229548748505\n",
      "2022-10-28 21:45:36.157002 Epoch 50, Training loss 0.35617608979661414\n",
      "2022-10-28 21:45:42.544285 Epoch 60, Training loss 0.31755396476451386\n",
      "2022-10-28 21:45:48.914805 Epoch 70, Training loss 0.2826795511106227\n",
      "2022-10-28 21:45:56.036558 Epoch 80, Training loss 0.2502235442082933\n",
      "2022-10-28 21:46:02.275982 Epoch 90, Training loss 0.21977652301813694\n",
      "2022-10-28 21:46:08.653578 Epoch 100, Training loss 0.19207787412278196\n",
      "Training and Validation Accuracy of model2 = Net(32)\n",
      "Accuracy train: 0.930733\n",
      "Accuracy val: 0.814667\n",
      "\n",
      "The model is overfit since the training accuracy is higher than the validation accuracy.\n"
     ]
    }
   ],
   "source": [
    "#Call the training function on the created training data loader, the created CNN  with n = 32, \n",
    "# negative log likelihood loss function, stochastic gradient descent optimizer,\n",
    "# the device you defined, and 100 epochs. Next, call validation accuracy function.\n",
    "#Is the model overfit? (Yes/No) Why? \n",
    "# (This can be compared to the fully connected network we created in the last set of exercises.)\n",
    "\n",
    "# move model to specified device\n",
    "print(f\"Training on device {device}.\")\n",
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "model2 = model2.to(device=device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer2 = optim.SGD(model2.parameters(), lr=learning_rate)\n",
    "n_epochs=100\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "\n",
    "training_loop(n_epochs=n_epochs, train_loader=train_loader, model=model2, loss_fn=loss_fn, optimizer=optimizer2, device=device)\n",
    "\n",
    "print(\"Training and Validation Accuracy of model2 = Net(32)\")\n",
    "validate(model=model2, train_loader=train_loader, val_loader=val_loader)\n",
    "\n",
    "print(\"\\nThe model is overfit since the training accuracy is higher than the validation accuracy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dde7111-bf9d-4a9b-b5df-f782586e60b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-28 21:46:09.618247 Epoch 1, Training loss 1.084126143252596\n",
      "2022-10-28 21:46:15.363517 Epoch 10, Training loss 0.721956385703797\n",
      "2022-10-28 21:46:21.729078 Epoch 20, Training loss 0.5965765701963547\n",
      "2022-10-28 21:46:27.899219 Epoch 30, Training loss 0.51014675003417\n",
      "2022-10-28 21:46:34.245993 Epoch 40, Training loss 0.4431341862424891\n",
      "2022-10-28 21:46:40.518281 Epoch 50, Training loss 0.3972970224441366\n",
      "2022-10-28 21:46:46.870352 Epoch 60, Training loss 0.36258569752916375\n",
      "2022-10-28 21:46:54.128976 Epoch 70, Training loss 0.3320204309326537\n",
      "2022-10-28 21:47:00.857053 Epoch 80, Training loss 0.30535245575803394\n",
      "2022-10-28 21:47:07.273492 Epoch 90, Training loss 0.28116863439691825\n",
      "2022-10-28 21:47:13.565209 Epoch 100, Training loss 0.2592972617834172\n",
      "Accuracy train: 0.907467\n",
      "Accuracy val: 0.821667\n",
      "The model is overfit since the training accuracy is higher than the validation accuracy.\n"
     ]
    }
   ],
   "source": [
    "#Next, let's consider L2 regularization with weight decay 0.002 for CNN with n = 32. \n",
    "# Is the model overfit? (Yes/No) Why?\n",
    "# optimizer accepts weight decay as input\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "model3 = Net(32).to(device=device)\n",
    "optimizer3 = optim.SGD(model3.parameters(), lr=learning_rate, weight_decay=0.002)\n",
    "training_loop(n_epochs=n_epochs, train_loader=train_loader, model=model3, loss_fn=loss_fn, optimizer=optimizer3, device=device)\n",
    "validate(model=model3, train_loader=train_loader, val_loader=val_loader)\n",
    "print('''The model is overfit since the training accuracy is higher than the validation accuracy.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b8e315a-0f42-4dbf-b641-6c11fbe206e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-28 21:47:14.522744 Epoch 1, Training loss 1.0447596453605814\n",
      "2022-10-28 21:47:20.213905 Epoch 10, Training loss 0.6446497010423782\n",
      "2022-10-28 21:47:26.672977 Epoch 20, Training loss 0.5031503773750143\n",
      "2022-10-28 21:47:32.910465 Epoch 30, Training loss 0.4266185052217321\n",
      "2022-10-28 21:47:39.225668 Epoch 40, Training loss 0.37924097383275945\n",
      "2022-10-28 21:47:45.519182 Epoch 50, Training loss 0.3437925416738429\n",
      "2022-10-28 21:47:52.618466 Epoch 60, Training loss 0.3143698365764415\n",
      "2022-10-28 21:47:59.796633 Epoch 70, Training loss 0.2878950150723153\n",
      "2022-10-28 21:48:06.311784 Epoch 80, Training loss 0.26431462878876544\n",
      "2022-10-28 21:48:12.844013 Epoch 90, Training loss 0.24269612193741696\n",
      "2022-10-28 21:48:19.263775 Epoch 100, Training loss 0.22147898173078578\n",
      "Accuracy train: 0.923800\n",
      "Accuracy val: 0.822333\n",
      "since the training accuracy is higher than the validation accuracy.\n"
     ]
    }
   ],
   "source": [
    "#Add a skip connection in your CNN from the output of second max pooling to the input of 3rd max pooling.\n",
    "#Train the updated CNN with the same parameters including (n = 32).\n",
    "#Is the model overfit? (Yes/No) Why?\n",
    "\n",
    "# Version of previous Net() CNN using skip connections a la ResNet\n",
    "class ResNet(nn.Module):\n",
    "    # n = number of output channels n after the first convolution\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, n, kernel_size=3, padding=1) # 3x3, 3 Channels -> n Channels\n",
    "        self.conv2 = nn.Conv2d(n, n//2, kernel_size=3, padding=1) # 3x3, n C -> n/2 C\n",
    "        self.conv3 = nn.Conv2d(n//2, n//2, kernel_size=3, padding=1) # 3x3, n/2 C -> n/4 C\n",
    "        \n",
    "        # turn multichannel 2D features into 1D vector\n",
    "        self.ch = 4 * 4 * (n//2) # W x H x num of kernels\n",
    "        self.fc1 = nn.Linear(self.ch, 32) # n/4 x n/4 x n/4\n",
    "        self.fc2 = nn.Linear(32, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2) # 32 x 32 x n -> kernel is 3\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2) # 16 x 16 x n\n",
    "        out1 = out\n",
    "        out = F.max_pool2d(torch.tanh(self.conv3(out)) + out1, 2) # Skip Connection\n",
    "        out = out.view(-1, self.ch) # n/4 * n/4 * n/4 # call view to turn it into B x N vector\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out\n",
    "\n",
    "# Train model with the same parameters (n=32)\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "model4 = ResNet(32).to(device=device)\n",
    "optimizer4 = optim.SGD(model4.parameters(), lr=learning_rate, weight_decay=0.002)\n",
    "training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    train_loader=train_loader,\n",
    "    model=model4,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer4,\n",
    "    device=device)\n",
    "\n",
    "\n",
    "validate(model=model4, train_loader=train_loader, val_loader=val_loader)\n",
    "print('''since the training accuracy is higher than the validation accuracy.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02c460b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-28 21:48:20.230913 Epoch 1, Training loss 1.0636494948508892\n",
      "2022-10-28 21:48:25.925853 Epoch 10, Training loss 0.6373084157071215\n",
      "2022-10-28 21:48:32.306407 Epoch 20, Training loss 0.5080725383251271\n",
      "2022-10-28 21:48:38.540143 Epoch 30, Training loss 0.43420869784152255\n",
      "2022-10-28 21:48:44.991761 Epoch 40, Training loss 0.38446929714781175\n",
      "2022-10-28 21:48:51.319364 Epoch 50, Training loss 0.34611960801672426\n",
      "2022-10-28 21:48:57.610758 Epoch 60, Training loss 0.31461222431761154\n",
      "2022-10-28 21:49:03.948139 Epoch 70, Training loss 0.287566935128354\n",
      "2022-10-28 21:49:10.089911 Epoch 80, Training loss 0.2628550377614955\n",
      "2022-10-28 21:49:16.435296 Epoch 90, Training loss 0.24069075454422767\n",
      "2022-10-28 21:49:22.791518 Epoch 100, Training loss 0.22019156496575537\n",
      "Accuracy train: 0.911600\n",
      "Accuracy val: 0.822000\n"
     ]
    }
   ],
   "source": [
    "# Train model with the same parameters (n=32)\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "model5 = ResNet(32).to(device=device)\n",
    "optimizer5 = optim.SGD(model5.parameters(), lr=learning_rate, weight_decay=0.002)\n",
    "training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    train_loader=train_loader,\n",
    "    model=model5,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer5,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "\n",
    "validate(model=model5, train_loader=train_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4ebfaac-1a04-4695-aa15-c83f86290c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-28 21:49:23.777695 Epoch 1, Training loss 1.0902992547826564\n",
      "2022-10-28 21:49:29.866585 Epoch 10, Training loss 0.8505581247045638\n",
      "2022-10-28 21:49:36.695218 Epoch 20, Training loss 0.749748404228941\n",
      "2022-10-28 21:49:43.625868 Epoch 30, Training loss 0.6906673886674516\n",
      "2022-10-28 21:49:50.582686 Epoch 40, Training loss 0.6562702217000596\n",
      "2022-10-28 21:49:58.317441 Epoch 50, Training loss 0.6304895234868881\n",
      "2022-10-28 21:50:05.201773 Epoch 60, Training loss 0.601687741279602\n",
      "2022-10-28 21:50:12.047203 Epoch 70, Training loss 0.581660072981043\n",
      "2022-10-28 21:50:18.917601 Epoch 80, Training loss 0.5793321301328375\n",
      "2022-10-28 21:50:25.740500 Epoch 90, Training loss 0.5601626330233634\n",
      "2022-10-28 21:50:32.584002 Epoch 100, Training loss 0.5537662220762131\n",
      "Accuracy train: 0.781533\n",
      "Accuracy val: 0.751000\n",
      "The difference between the training and validation accuracy is around 1 percent, so the model is slightly\n",
      "overfit, but well fit compared to the previous CNNs.\n"
     ]
    }
   ],
   "source": [
    "#Consider dropout layers after each max pooling in the original CNN, where the probability of zeroing output features is 30%.\n",
    "#Train the updated CNN with the same parameters including (n = 32).\n",
    "#Is the model overfit? (Yes/No) Why?\n",
    "\n",
    "# padding: keep the output image size the same\n",
    "class NetDropout(nn.Module):\n",
    "    # n = number of output channels n after the first convolution\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, n, kernel_size=3, padding=1) # 3x3, 3 Channels -> n Channels\n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.3)\n",
    "        self.conv2 = nn.Conv2d(n, n//2, kernel_size=3, padding=1) # 3x3, n C -> n/2 C\n",
    "        self.conv2_dropout = nn.Dropout2d(p=0.3)\n",
    "        self.conv3 = nn.Conv2d(n//2, n//2, kernel_size=3, padding=1) # 3x3, n/2 C -> n/4 C\n",
    "        self.conv3_dropout = nn.Dropout2d(p=0.3)\n",
    "        \n",
    "        # turn multichannel 2D features into 1D vector\n",
    "        self.ch = 4 * 4 * (n//2) # W x H x num of kernels\n",
    "        self.fc1 = nn.Linear(self.ch, 32) # n/4 x n/4 x n/4\n",
    "        self.fc2 = nn.Linear(32, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2) # 32 x 32 x n -> kernel is 3\n",
    "        out = self.conv1_dropout(out)\n",
    "        \n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2) # 16 x 16 x n\n",
    "        out = self.conv2_dropout(out)\n",
    "        \n",
    "        out = F.max_pool2d(torch.tanh(self.conv3(out)), 2) # 8 x 8 x n\n",
    "        out = self.conv3_dropout(out)\n",
    "        \n",
    "        out = out.view(-1, self.ch) # n/4 * n/4 * n/4 # call view to turn it into B x N vector\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "model6 = NetDropout(32).to(device=device)\n",
    "optimizer6 = optim.SGD(model6.parameters(), lr=learning_rate)\n",
    "training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    train_loader=train_loader,\n",
    "    model=model6,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer6,\n",
    "    device=device)\n",
    "\n",
    "\n",
    "validate(model=model6, train_loader=train_loader, val_loader=val_loader)\n",
    "print('''The difference between the training and validation accuracy is around 1 percent, so the model is slightly\n",
    "overfit, but well fit compared to the previous CNNs.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33917fa1-51d7-42cb-808d-7caa06ef8908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CNN that worked better was the CNN+Skip layer in terms of highest training and validation accuracies with\n",
      "the lowest overfitting. However, if we are looking for a well fit CNN then the CNN+Dropout performed best since it had around\n",
      "1% difference between the training and validation data.\n"
     ]
    }
   ],
   "source": [
    "#Considering all the modifications which one works better? Plain CNN, CNN+L2, CNN+Skip, CNN+Dropout?\n",
    "print('''The CNN that worked better was the CNN+Skip layer in terms of highest training and validation accuracies with\n",
    "the lowest overfitting. However, if we are looking for a well fit CNN then the CNN+Dropout performed best since it had around\n",
    "1% difference between the training and validation data.''')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0acaf148705ed9ed86cc5cad12259d7985e30670e5686e5f55604a9b3b84a55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
